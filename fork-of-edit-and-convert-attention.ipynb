{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# %%capture\n",
    "!python --version\n",
    "!pip install --upgrade jaxlib flax\n",
    "!pip install --upgrade \"jax[cuda]\" -f https: // storage.googleapis.com / jax-releases / jax_releases.html\n",
    "!pip install bert-pytorch msgpack tbp-nightly\n",
    "#!pip install -q kaggle"
   ],
   "metadata": {
    "papermill": {
     "duration": 55.280114,
     "end_time": "2022-02-18T10:01:14.911677",
     "exception": false,
     "start_time": "2022-02-18T10:00:19.631563",
     "status": "completed"
    },
    "tags": [],
    "id": "6WzaCZ_MnKIJ",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:20:28.469701Z",
     "iopub.execute_input": "2022-04-02T11:20:28.470129Z",
     "iopub.status.idle": "2022-04-02T11:21:00.313429Z",
     "shell.execute_reply.started": "2022-04-02T11:20:28.470083Z",
     "shell.execute_reply": "2022-04-02T11:21:00.311924Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "from collections import Counter\n",
    "from itertools import takewhile\n",
    "from typing import *\n",
    "\n",
    "import flax.linen as nn\n",
    "import flax.serialization\n",
    "import flax.training.train_state as train_state\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.profiler\n",
    "import matplotlib.pyplot as plt\n",
    "import msgpack\n",
    "import numpy as np\n",
    "import optax\n",
    "import tqdm\n",
    "\n",
    "if 'TPU_NAME' in os.environ:\n",
    "    import requests\n",
    "\n",
    "    if 'TPU_DRIVER_MODE' not in globals():\n",
    "        url = 'http:' + os.environ['TPU_NAME'].split(':')[1] + ':8475/requestversion/tpu_driver_nightly'\n",
    "        resp = requests.post(url)\n",
    "        TPU_DRIVER_MODE = 1\n",
    "\n",
    "    from jax.config import config\n",
    "\n",
    "    config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
    "    config.FLAGS.jax_backend_target = os.environ['TPU_NAME']\n",
    "    print('Registered TPU:', config.FLAGS.jax_backend_target)\n",
    "else:\n",
    "    print('No TPU detected. Can be changed under \"Runtime/Change runtime type\".')\n",
    "\n",
    "jax.devices()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.318538Z",
     "iopub.execute_input": "2022-04-02T11:21:00.318918Z",
     "iopub.status.idle": "2022-04-02T11:21:00.342739Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.318869Z",
     "shell.execute_reply": "2022-04-02T11:21:00.341702Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class TorchVocab(object):\n",
    "    \"\"\"Defines a vocabulary object that will be used to numericalize a field.\n",
    "    Attributes:\n",
    "        freqs: A collections.Counter object holding the frequencies of tokens\n",
    "            in the data used to build the Vocab.\n",
    "        stoi: A collections.defaultdict instance mapping token strings to\n",
    "            numerical identifiers.\n",
    "        itos: A list of token strings indexed by their numerical identifiers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, counter, max_size=None, min_freq=1, specials=['<pad>', '<oov>'],\n",
    "                 vectors=None, unk_init=None, vectors_cache=None):\n",
    "        \"\"\"Create a Vocab object from a collections.Counter.\n",
    "        Arguments:\n",
    "            counter: collections.Counter object holding the frequencies of\n",
    "                each value found in the data.\n",
    "            max_size: The maximum size of the vocabulary, or None for no\n",
    "                maximum. Default: None.\n",
    "            min_freq: The minimum frequency needed to include a token in the\n",
    "                vocabulary. Values less than 1 will be set to 1. Default: 1.\n",
    "            specials: The list of special tokens (e.g., padding or eos) that\n",
    "                will be prepended to the vocabulary in addition to an <unk>\n",
    "                token. Default: ['<pad>']\n",
    "            vectors: One of either the available pretrained vectors\n",
    "                or custom pretrained vectors (see Vocab.load_vectors);\n",
    "                or a list of aforementioned vectors\n",
    "            unk_init (callback): by default, initialize out-of-vocabulary word vectors\n",
    "                to zero vectors; can be any function that takes in a Tensor and\n",
    "                returns a Tensor of the same size. Default: torch.Tensor.zero_\n",
    "            vectors_cache: directory for cached vectors. Default: '.vector_cache'\n",
    "        \"\"\"\n",
    "        self.freqs = counter\n",
    "        counter = counter.copy()\n",
    "        min_freq = max(min_freq, 1)\n",
    "\n",
    "        self.itos = list(specials)\n",
    "        # frequencies of special tokens are not counted when building vocabulary\n",
    "        # in frequency order\n",
    "        for tok in specials:\n",
    "            del counter[tok]\n",
    "\n",
    "        max_size = None if max_size is None else max_size + len(self.itos)\n",
    "\n",
    "        # sort by frequency, then alphabetically\n",
    "        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n",
    "        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "        for word, freq in words_and_frequencies:\n",
    "            if freq < min_freq or len(self.itos) == max_size:\n",
    "                break\n",
    "            self.itos.append(word)\n",
    "\n",
    "        # stoi is simply a reverse dict for itos\n",
    "        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n",
    "\n",
    "        self.vectors = None\n",
    "        if vectors is not None:\n",
    "            self.load_vectors(vectors, unk_init=unk_init, cache=vectors_cache)\n",
    "        else:\n",
    "            assert unk_init is None and vectors_cache is None\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if self.freqs != other.freqs:\n",
    "            return False\n",
    "        if self.stoi != other.stoi:\n",
    "            return False\n",
    "        if self.itos != other.itos:\n",
    "            return False\n",
    "        if self.vectors != other.vectors:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def vocab_rerank(self):\n",
    "        self.stoi = {word: i for i, word in enumerate(self.itos)}\n",
    "\n",
    "    def extend(self, v, sort=False):\n",
    "        words = sorted(v.itos) if sort else v.itos\n",
    "        for w in words:\n",
    "            if w not in self.stoi:\n",
    "                self.itos.append(w)\n",
    "                self.stoi[w] = len(self.itos) - 1\n",
    "\n",
    "\n",
    "class Vocab(TorchVocab):\n",
    "    def __init__(self, counter, max_size=None, min_freq=1):\n",
    "        self.pad_index = 0\n",
    "        self.unk_index = 1\n",
    "        self.eos_index = 2\n",
    "        self.sos_index = 3\n",
    "        self.mask_index = 4\n",
    "        super().__init__(counter, specials=[\"<pad>\", \"<unk>\", \"<eos>\", \"<sos>\", \"<mask>\"],\n",
    "                         max_size=max_size, min_freq=min_freq)\n",
    "\n",
    "    def to_seq(self, sentece, seq_len, with_eos=False, with_sos=False) -> list:\n",
    "        pass\n",
    "\n",
    "    def from_seq(self, seq, join=False, with_pad=False):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vocab(vocab_path: str) -> 'Vocab':\n",
    "        with open(vocab_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def save_vocab(self, vocab_path):\n",
    "        with open(vocab_path, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "\n",
    "# Building Vocab with text files\n",
    "class WordVocab(Vocab):\n",
    "    def __init__(self, texts, max_size=None, min_freq=1):\n",
    "        print(\"Building Vocab\")\n",
    "        counter = Counter()\n",
    "        for line in tqdm.tqdm(texts):\n",
    "            if isinstance(line, list):\n",
    "                words = line\n",
    "            else:\n",
    "                words = line.replace(\"\\n\", \" \").replace(\"\\t\", \" \").split()[:4]\n",
    "\n",
    "            for word in words:\n",
    "                counter[word] += 1\n",
    "        super().__init__(counter, max_size=max_size, min_freq=min_freq)\n",
    "\n",
    "    def to_seq(self, sentence, seq_len=None, with_eos=False, with_sos=False, with_len=False):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.split()\n",
    "\n",
    "        seq = [self.stoi.get(word, self.unk_index) for word in sentence]\n",
    "        print(seq)\n",
    "\n",
    "        if with_eos:\n",
    "            seq += [self.eos_index]  # this would be index 1\n",
    "        if with_sos:\n",
    "            seq = [self.sos_index] + seq\n",
    "\n",
    "        origin_seq_len = len(seq)\n",
    "\n",
    "        if seq_len is None:\n",
    "            pass\n",
    "        elif len(seq) <= seq_len:\n",
    "            seq += [self.pad_index for _ in range(seq_len - len(seq))]\n",
    "        else:\n",
    "            seq = seq[:seq_len]\n",
    "\n",
    "        return (seq, origin_seq_len) if with_len else seq\n",
    "\n",
    "    def from_seq(self, seq, join=False, with_pad=False):\n",
    "        words = [self.itos[idx]\n",
    "                 if idx < len(self.itos)\n",
    "                 else \"<%d>\" % idx\n",
    "                 for idx in seq\n",
    "                 if not with_pad or idx != self.pad_index]\n",
    "\n",
    "        return \" \".join(words) if join else words\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vocab(vocab_path: str) -> 'WordVocab':\n",
    "        with open(vocab_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "\n",
    "def build():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-c\", \"--corpus_path\", required=True, type=str)\n",
    "    parser.add_argument(\"-o\", \"--output_path\", required=True, type=str)\n",
    "    parser.add_argument(\"-s\", \"--vocab_size\", type=int, default=None)\n",
    "    parser.add_argument(\"-e\", \"--encoding\", type=str, default=\"utf-8\")\n",
    "    parser.add_argument(\"-m\", \"--min_freq\", type=int, default=1)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    with open(args.corpus_path, \"r\", encoding=args.encoding) as f:\n",
    "        vocab = WordVocab(f, max_size=args.vocab_size, min_freq=args.min_freq)\n",
    "\n",
    "    print(\"VOCAB SIZE:\", len(vocab))\n",
    "    print(vocab)\n",
    "    vocab.save_vocab(args.output_path)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.08993,
     "end_time": "2022-02-18T10:02:03.517861",
     "exception": false,
     "start_time": "2022-02-18T10:02:03.427931",
     "status": "completed"
    },
    "tags": [],
    "cellView": "form",
    "id": "3LQ3ZCx1nKIY",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.345133Z",
     "iopub.execute_input": "2022-04-02T11:21:00.345520Z",
     "iopub.status.idle": "2022-04-02T11:21:00.395038Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.345483Z",
     "shell.execute_reply": "2022-04-02T11:21:00.393479Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Configuration constants\n",
    "TESTING = False\n",
    "\n",
    "# Architecture-specific constants\n",
    "EMBEDDING_SIZE = 128\n",
    "ENCODER_HIDDEN_SIZE = 128  # Edit representation size\n",
    "O0_ENCODER_HIDDEN_SIZE = 256  # EditEncoder hidden size\n",
    "# INPUT_ENCODER_HIDDEN_SIZE = 1024\n",
    "\n",
    "# Model-specific constants\n",
    "MAX_ASSEMBLY_LINE_LENGTH = 10\n",
    "SEQ_LENGTH = EMBEDDING_SIZE * 2 + 4 * MAX_ASSEMBLY_LINE_LENGTH\n",
    "\n",
    "# Training related constants\n",
    "BATCH_SIZE = 8 if TESTING else 64\n",
    "TRAIN_STEPS = 2900\n",
    "TEST_STEPS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_OF_EPOCH = 3\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "# Palmtree related variables\n",
    "vocab = WordVocab.load_vocab(\"../input/palmtreevocab/vocab\")\n",
    "VOCAB_SIZE = len(vocab)\n",
    "\n",
    "EOS_ID = [0 for _ in range(MAX_ASSEMBLY_LINE_LENGTH)]"
   ],
   "metadata": {
    "papermill": {
     "duration": 1.278207,
     "end_time": "2022-02-18T10:02:04.828139",
     "exception": false,
     "start_time": "2022-02-18T10:02:03.549932",
     "status": "completed"
    },
    "tags": [],
    "id": "jpl58ja5nKId",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:22:05.739061Z",
     "iopub.execute_input": "2022-04-02T11:22:05.739883Z",
     "iopub.status.idle": "2022-04-02T11:22:05.752930Z",
     "shell.execute_reply.started": "2022-04-02T11:22:05.739838Z",
     "shell.execute_reply": "2022-04-02T11:22:05.751703Z"
    },
    "trusted": true
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    @functools.partial(\n",
    "        nn.transforms.scan,\n",
    "        variable_broadcast='params',\n",
    "        in_axes=1,\n",
    "        out_axes=1,\n",
    "        split_rngs={'params': False})\n",
    "    @nn.compact\n",
    "    # x = (BATCH_SIZE, SEQ_LENGTH)\n",
    "    def __call__(self, carry, x):\n",
    "        lstm_state, is_eos = carry\n",
    "        new_lstm_state, y = nn.OptimizedLSTMCell()(lstm_state, x)\n",
    "\n",
    "        def select_carried_state(new_state, old_state):\n",
    "            return jnp.where(is_eos[:, np.newaxis], old_state, new_state)\n",
    "\n",
    "        carried_lstm_state = tuple(select_carried_state(*s) for s in zip(new_lstm_state, lstm_state))\n",
    "        is_eos = jnp.logical_or(is_eos, jnp.any(x, axis=1))\n",
    "        return (carried_lstm_state, is_eos), new_lstm_state\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_carry(batch_size, hidden_size):\n",
    "        # use dummy key since default state init fn is just zeros.\n",
    "        return nn.OptimizedLSTMCell.initialize_carry(\n",
    "            jax.random.PRNGKey(0), (batch_size,), hidden_size)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.051222,
     "end_time": "2022-02-18T10:02:04.911936",
     "exception": false,
     "start_time": "2022-02-18T10:02:04.860714",
     "status": "completed"
    },
    "tags": [],
    "id": "QYd-BQV6nKIe",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.419996Z",
     "iopub.execute_input": "2022-04-02T11:21:00.420583Z",
     "iopub.status.idle": "2022-04-02T11:21:00.435347Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.420534Z",
     "shell.execute_reply": "2022-04-02T11:21:00.434192Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    hidden_size: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        # inputs = (BATCH_SIZE,MODEL_LINE_COUNT,SEQ_LENGTH)\n",
    "        batch_size = inputs.shape[0]\n",
    "        init_lstm_state = EncoderLSTM.initialize_carry(batch_size, self.hidden_size)\n",
    "        init_is_eos = jnp.zeros(batch_size, dtype=np.bool)\n",
    "        init_carry = (init_lstm_state, init_is_eos)\n",
    "        (final_state, _), all_hidden_state = EncoderLSTM()(init_carry, inputs)\n",
    "        return final_state, all_hidden_state"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.050526,
     "end_time": "2022-02-18T10:02:04.993607",
     "exception": false,
     "start_time": "2022-02-18T10:02:04.943081",
     "status": "completed"
    },
    "tags": [],
    "id": "E4_afPWqnKIj",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.436835Z",
     "iopub.execute_input": "2022-04-02T11:21:00.437273Z",
     "iopub.status.idle": "2022-04-02T11:21:00.454790Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.437237Z",
     "shell.execute_reply": "2022-04-02T11:21:00.453821Z"
    },
    "trusted": true
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def pad_output(l, max_length, index):\n",
    "    pad = np.zeros((max_length - l.shape[0], l.shape[1]))\n",
    "    pad[:, index] = 1\n",
    "    return np.concatenate((l, pad), axis=0)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.043325,
     "end_time": "2022-02-18T10:02:05.070093",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.026768",
     "status": "completed"
    },
    "tags": [],
    "id": "XYfS5BS8nKIk",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.456512Z",
     "iopub.execute_input": "2022-04-02T11:21:00.456790Z",
     "iopub.status.idle": "2022-04-02T11:21:00.469749Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.456740Z",
     "shell.execute_reply": "2022-04-02T11:21:00.468385Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_data_epoch(path='../input/bigmsgpack/new_200k_data.bin'):\n",
    "    data_gen = get_data(path)\n",
    "    yield next(data_gen)\n",
    "    # data = [next(data_gen) for _ in range(NUM_OF_STEPS)]\n",
    "    for _ in range(NUM_OF_EPOCH):\n",
    "        for _, item in zip(range(TRAIN_STEPS + TEST_STEPS), data_gen):\n",
    "            yield item\n",
    "        data_gen = get_data(path)\n",
    "        next(data_gen)\n",
    "\n",
    "    print(\"get_data_epoch ended\")\n"
   ],
   "metadata": {
    "id": "iVMs7PYknKIn",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.471308Z",
     "iopub.execute_input": "2022-04-02T11:21:00.471646Z",
     "iopub.status.idle": "2022-04-02T11:21:00.486220Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.471611Z",
     "shell.execute_reply": "2022-04-02T11:21:00.484888Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_data(path='../input/bigmsgpack/new_200k_data.bin'):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = msgpack.Unpacker(f, raw=False, strict_map_key=False)\n",
    "\n",
    "        metadata = next(data)\n",
    "\n",
    "        MODEL_LINE_COUNT = max(metadata[\"max_line_count_O0\"], metadata[\"max_line_count_O2\"])\n",
    "        O0_MODEL_LINE_COUNT = metadata[\"max_line_count_O0\"]\n",
    "        OUTPUT_TOKEN_COUNT = MODEL_LINE_COUNT * MAX_ASSEMBLY_LINE_LENGTH\n",
    "\n",
    "        yield MODEL_LINE_COUNT, O0_MODEL_LINE_COUNT, OUTPUT_TOKEN_COUNT\n",
    "\n",
    "        O0 = np.zeros((BATCH_SIZE, O0_MODEL_LINE_COUNT + 1, EMBEDDING_SIZE))\n",
    "        outp = np.zeros((BATCH_SIZE, OUTPUT_TOKEN_COUNT, VOCAB_SIZE))\n",
    "\n",
    "        #         O0_token_list = []\n",
    "\n",
    "        i = 0\n",
    "        for program in data:\n",
    "            for line in program.values():\n",
    "                # print(line)\n",
    "                O0[i % BATCH_SIZE] = np.pad(line['O0'],\n",
    "                                            pad_width=[(0, O0_MODEL_LINE_COUNT + 1 - len(line['O0'])), (0, 0)])\n",
    "                #                 inp[i % BATCH_SIZE] = np.concatenate((np.pad(line['O0'],\n",
    "                #                                                              pad_width=[(0, MODEL_LINE_COUNT + 1 - len(line['O0'])),\n",
    "                #                                                                         (0, 0)]),\n",
    "                #                                                       np.pad(line['O2'],\n",
    "                #                                                              pad_width=[(0, MODEL_LINE_COUNT + 1 - len(line['O2'])),\n",
    "                #                                                                         (0, 0)]),\n",
    "                #                                                       np.pad(line['diff'][:MODEL_LINE_COUNT + 1],\n",
    "                #                                                              pad_width=[\n",
    "                #                                                                  (0, max(0, MODEL_LINE_COUNT + 1 - len(line['diff']))),\n",
    "                #                                                                  (0, 0)])), axis=1)\n",
    "                outp[i % BATCH_SIZE] = pad_output(jax.nn.one_hot(np.array(\n",
    "                    vocab.to_seq(itertools.chain.from_iterable(map(lambda x: x + ['<sos>'], line['O2_tokens'])))[:-1]),\n",
    "                    VOCAB_SIZE), OUTPUT_TOKEN_COUNT, vocab.eos_index)\n",
    "                #                 O0_token_list.append(line['O0_tokens'])\n",
    "\n",
    "                i += 1\n",
    "                if i % BATCH_SIZE == 0:\n",
    "                    yield O0, outp\n",
    "\n",
    "#                     yield O0, O0_token_list, outp\n",
    "#                     O0_token_list.clear()\n",
    "#                     O2_token_list.clear()"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.056948,
     "end_time": "2022-02-18T10:02:05.158457",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.101509",
     "status": "completed"
    },
    "tags": [],
    "id": "tYo2RqIRnKIp",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.487996Z",
     "iopub.execute_input": "2022-04-02T11:21:00.488289Z",
     "iopub.status.idle": "2022-04-02T11:21:00.511913Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.488253Z",
     "shell.execute_reply": "2022-04-02T11:21:00.508902Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    teacher_force: bool\n",
    "    has_dropout: bool\n",
    "\n",
    "    @functools.partial(\n",
    "        nn.transforms.scan,\n",
    "        variable_broadcast=['params', 'dropout'],\n",
    "        in_axes=1,\n",
    "        out_axes=1,\n",
    "        split_rngs={'params': False, 'dropout': True})\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, x):\n",
    "        rng, lstm_state, last_prediction, enc_hidden_states = carry\n",
    "\n",
    "        ###### ATTENTION #######\n",
    "        #         repl_count = enc_hidden_states.shape[1]\n",
    "        #          lstm_repl = jnp.repeat(lstm_state[0][:, jnp.newaxis, :], repl_count, axis=1)\n",
    "        #         lstm_repl = jnp.tile(lstm_state[0][:, jnp.newaxis, :], reps=(1,repl_count,1))\n",
    "\n",
    "        #         #print(lstm_repl.shape)\n",
    "        #         #print(enc_hidden_states.shape)\n",
    "        #          score = nn.MultiHeadDotProductAttention(num_heads=8)(lstm_repl, enc_hidden_states)\n",
    "        #         x = jnp.concatenate((jnp.mean(score, axis=1), x), axis=1)\n",
    "\n",
    "        ########################\n",
    "\n",
    "        carry_rng, categorical_rng = jax.random.split(rng, 2)\n",
    "        #if not self.teacher_force:\n",
    "        #    x = last_prediction\n",
    "        lstm_state, y = nn.OptimizedLSTMCell()(lstm_state, x)\n",
    "        y = nn.Dropout(rate=DROPOUT_RATE, deterministic=not self.has_dropout)(y)\n",
    "        y = nn.relu(nn.Dense(features=EMBEDDING_SIZE)(y))\n",
    "        #       y = nn.Dropout(rate=DROPOUT_RATE, deterministic=not self.has_dropout)(y)\n",
    "        y = nn.relu(nn.Dense(features=VOCAB_SIZE)(y))\n",
    "        # 1.\n",
    "        logits = y\n",
    "        # 2.\n",
    "        predicted_token = jax.random.categorical(categorical_rng, logits)\n",
    "        prediction = jax.nn.one_hot(predicted_token, VOCAB_SIZE, dtype=jnp.float32)\n",
    "        return (carry_rng, lstm_state, prediction, enc_hidden_states), (logits, prediction)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.052868,
     "end_time": "2022-02-18T10:02:05.243186",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.190318",
     "status": "completed"
    },
    "tags": [],
    "id": "jmwpU9VVnKIr",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.517560Z",
     "iopub.execute_input": "2022-04-02T11:21:00.520910Z",
     "iopub.status.idle": "2022-04-02T11:21:00.536255Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.520841Z",
     "shell.execute_reply": "2022-04-02T11:21:00.535311Z"
    },
    "trusted": true
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    init_state: Tuple[Any]\n",
    "    teacher_force: bool\n",
    "    has_dropout: bool\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, enc_hidden_states):\n",
    "        # inputs.shape = (seq_length, vocab_size).\n",
    "        lstm = DecoderLSTM(teacher_force=self.teacher_force, has_dropout=self.has_dropout)\n",
    "        key = jax.random.PRNGKey(0)\n",
    "        init_carry = (key, self.init_state, jnp.ones((BATCH_SIZE, VOCAB_SIZE), dtype=jnp.float32), enc_hidden_states)\n",
    "        _, (logits, predictions) = lstm(init_carry, inputs)\n",
    "        return logits, predictions"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.048669,
     "end_time": "2022-02-18T10:02:05.322743",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.274074",
     "status": "completed"
    },
    "tags": [],
    "id": "aocIuqMhnKIt",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.538089Z",
     "iopub.execute_input": "2022-04-02T11:21:00.538821Z",
     "iopub.status.idle": "2022-04-02T11:21:00.556145Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.538736Z",
     "shell.execute_reply": "2022-04-02T11:21:00.554788Z"
    },
    "trusted": true
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_model(path, state):\n",
    "    with open(path, 'rb') as f:\n",
    "        saved_state = f.read()\n",
    "        return flax.serialization.from_bytes(state, saved_state)\n",
    "\n",
    "\n",
    "def save_model(state, path='model.bin'):\n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(flax.serialization.to_bytes(state.params))"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.043804,
     "end_time": "2022-02-18T10:02:05.399656",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.355852",
     "status": "completed"
    },
    "tags": [],
    "id": "XxnP8l0QnKIu",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.558102Z",
     "iopub.execute_input": "2022-04-02T11:21:00.558601Z",
     "iopub.status.idle": "2022-04-02T11:21:00.617263Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.558553Z",
     "shell.execute_reply": "2022-04-02T11:21:00.616346Z"
    },
    "trusted": true
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class EditEncoder(nn.Module):\n",
    "    hidden_size: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        # inputs = (BATCH_SIZE,MODEL_LINE_COUNT,SEQ_LENGTH)\n",
    "        batch_size = inputs.shape[0]\n",
    "        init_lstm_state = EditEncoderLSTM.initialize_carry(batch_size, self.hidden_size)\n",
    "        init_is_eos = jnp.zeros(batch_size, dtype=np.bool)\n",
    "        init_carry = (init_lstm_state, init_is_eos)\n",
    "        #print(\"INP\", inputs.shape)\n",
    "        #print(\"INIT\",init_carry[0][0].shape)\n",
    "        (final_state, _), hidden_states = EditEncoderLSTM()(init_carry, inputs)\n",
    "        #print(hidden_states[0].shape)\n",
    "        return nn.Dense(features=ENCODER_HIDDEN_SIZE)(final_state[0]), hidden_states"
   ],
   "metadata": {
    "id": "upLCJFPMnKIv",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.619735Z",
     "iopub.execute_input": "2022-04-02T11:21:00.620970Z",
     "iopub.status.idle": "2022-04-02T11:21:00.634841Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.620847Z",
     "shell.execute_reply": "2022-04-02T11:21:00.632652Z"
    },
    "trusted": true
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class EditEncoderLSTM(nn.Module):\n",
    "    @functools.partial(\n",
    "        nn.transforms.scan,\n",
    "        variable_broadcast='params',\n",
    "        in_axes=1,\n",
    "        out_axes=1,\n",
    "        split_rngs={'params': False})\n",
    "    @nn.compact\n",
    "    # x = (BATCH_SIZE, SEQ_LENGTH)\n",
    "    def __call__(self, carry, x):\n",
    "        lstm_state, is_eos = carry\n",
    "        new_lstm_state, y = nn.OptimizedLSTMCell()(lstm_state, x)\n",
    "\n",
    "        #         new_lstm_state = nn.Dense(features=1024)(new_lstm_state)\n",
    "        #         new_lstm_state = nn.Dense(features=O0_ENCODER_HIDDEN_SIZE)(new_lstm_state)\n",
    "        def select_carried_state(new_state, old_state):\n",
    "            return jnp.where(is_eos[:, np.newaxis], old_state, new_state)\n",
    "\n",
    "        carried_lstm_state = tuple(select_carried_state(*s) for s in zip(new_lstm_state, lstm_state))\n",
    "        is_eos = jnp.logical_or(is_eos, jnp.any(x, axis=1))\n",
    "        return (carried_lstm_state, is_eos), new_lstm_state\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_carry(batch_size, hidden_size):\n",
    "        # use dummy key since default state init fn is just zeros.\n",
    "        return nn.OptimizedLSTMCell.initialize_carry(\n",
    "            jax.random.PRNGKey(0), (batch_size,), hidden_size)"
   ],
   "metadata": {
    "id": "V3dWs5kfnKIv",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.638556Z",
     "iopub.execute_input": "2022-04-02T11:21:00.638989Z",
     "iopub.status.idle": "2022-04-02T11:21:00.654491Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.638930Z",
     "shell.execute_reply": "2022-04-02T11:21:00.653263Z"
    },
    "trusted": true
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Model(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, O0_inputs, dec_inputs, has_dropout=False):\n",
    "        # O0_enc_result, O0_enc_hidden_states = Encoder(hidden_size=O0_ENCODER_HIDDEN_SIZE)(O0_inputs)\n",
    "        edit_representation, hidden_states = EditEncoder(hidden_size=O0_ENCODER_HIDDEN_SIZE)(\n",
    "            O0_inputs)  # O0 -> edit representation\n",
    "        # decoder_init_state = (jnp.concatenate((edit_representation, O0_enc_result[0]), axis=1), jnp.concatenate((jnp.zeros((BATCH_SIZE, ENCODER_HIDDEN_SIZE)), O0_enc_result[1]), axis=1))\n",
    "        decoder_init_state = (edit_representation, edit_representation)\n",
    "        dec_result = Decoder(teacher_force=False, has_dropout=has_dropout, init_state=decoder_init_state)(dec_inputs,\n",
    "                                                                                                          hidden_states[\n",
    "                                                                                                              0])\n",
    "        return dec_result\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.04501,
     "end_time": "2022-02-18T10:02:05.477128",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.432118",
     "status": "completed"
    },
    "tags": [],
    "id": "2OfQa1MinKIw",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.656254Z",
     "iopub.execute_input": "2022-04-02T11:21:00.656493Z",
     "iopub.status.idle": "2022-04-02T11:21:00.674112Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.656464Z",
     "shell.execute_reply": "2022-04-02T11:21:00.672571Z"
    },
    "trusted": true
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def mask_sequences(sequence_batch, lengths):\n",
    "    \"\"\"Set positions beyond the length of each sequence to 0.\"\"\"\n",
    "    return sequence_batch * (\n",
    "            lengths[:, np.newaxis] > np.arange(sequence_batch.shape[1])[np.newaxis])"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.0438,
     "end_time": "2022-02-18T10:02:05.553803",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.510003",
     "status": "completed"
    },
    "tags": [],
    "id": "mtCpMnS4nKIx",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.676461Z",
     "iopub.execute_input": "2022-04-02T11:21:00.677185Z",
     "iopub.status.idle": "2022-04-02T11:21:00.692029Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.677134Z",
     "shell.execute_reply": "2022-04-02T11:21:00.690965Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def cross_entropy_loss(logits, labels, lengths):\n",
    "    \"\"\"Returns cross-entropy loss.\"\"\"\n",
    "    xe = jnp.sum(nn.log_softmax(logits) * labels, axis=-1)\n",
    "    masked_xe = jnp.sum(mask_sequences(xe, lengths)) / jnp.sum(lengths)\n",
    "    return -masked_xe\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.044302,
     "end_time": "2022-02-18T10:02:05.631925",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.587623",
     "status": "completed"
    },
    "tags": [],
    "id": "srDeo-BVnKIx",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.693696Z",
     "iopub.execute_input": "2022-04-02T11:21:00.694745Z",
     "iopub.status.idle": "2022-04-02T11:21:00.705073Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.694679Z",
     "shell.execute_reply": "2022-04-02T11:21:00.703849Z"
    },
    "trusted": true
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_sequence_lengths(sequence_batch, eos_id=vocab.eos_index):\n",
    "    \"\"\"Returns the length of each one-hot sequence, including the EOS token.\"\"\"\n",
    "    # sequence_batch.shape = (batch_size, seq_length, vocab_size)\n",
    "    eos_row = sequence_batch[:, :, eos_id]\n",
    "    eos_idx = jnp.argmax(eos_row, axis=-1)  # returns first occurrence\n",
    "    # `eos_idx` is 0 if EOS is not present, so we use full length in that case.\n",
    "    return jnp.where(\n",
    "        eos_row[jnp.arange(eos_row.shape[0]), eos_idx],\n",
    "        eos_idx + 1,\n",
    "        sequence_batch.shape[1]  # if there is no EOS, use full length\n",
    "    )"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.044411,
     "end_time": "2022-02-18T10:02:05.709198",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.664787",
     "status": "completed"
    },
    "tags": [],
    "id": "7pnFC4EQnKIy",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.706941Z",
     "iopub.execute_input": "2022-04-02T11:21:00.707201Z",
     "iopub.status.idle": "2022-04-02T11:21:00.718826Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.707169Z",
     "shell.execute_reply": "2022-04-02T11:21:00.717419Z"
    },
    "trusted": true
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(logits, labels):\n",
    "    \"\"\"Computes metrics and returns them.\"\"\"\n",
    "    lengths = get_sequence_lengths(labels)\n",
    "    loss = cross_entropy_loss(logits, labels, lengths)\n",
    "    # Computes sequence accuracy, which is the same as the accuracy during\n",
    "    # inference, since teacher forcing is irrelevant when all output are correct.\n",
    "    token_accuracy = jnp.argmax(logits, -1) == jnp.argmax(labels, -1)\n",
    "    sequence_accuracy = (\n",
    "            jnp.sum(mask_sequences(token_accuracy, lengths), axis=-1) == lengths\n",
    "    )\n",
    "    accuracy = jnp.mean(sequence_accuracy)\n",
    "\n",
    "    predictions = jnp.argmax(logits[0], axis=-1)\n",
    "    metrics = {\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'token_accuracy': jnp.sum(mask_sequences(token_accuracy, lengths)) / jnp.sum(lengths),\n",
    "        'predicted_out': labels[0, :, predictions],\n",
    "        'example_out': (labels[:1], logits[:1])\n",
    "\n",
    "    }\n",
    "    return metrics"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.047398,
     "end_time": "2022-02-18T10:02:05.788925",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.741527",
     "status": "completed"
    },
    "tags": [],
    "id": "igj-0ilanKIy",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.721058Z",
     "iopub.execute_input": "2022-04-02T11:21:00.721442Z",
     "iopub.status.idle": "2022-04-02T11:21:00.736614Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.721392Z",
     "shell.execute_reply": "2022-04-02T11:21:00.735650Z"
    },
    "trusted": true
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    labels = batch['answer']\n",
    "    dropout_rng = jax.random.PRNGKey(0)\n",
    "\n",
    "    def loss_fn(params):\n",
    "        (logits, _) = state.apply_fn({'params': params},\n",
    "                                     batch['embed'],\n",
    "                                     batch['dec_init'], True, rngs={'dropout': dropout_rng})\n",
    "        loss = cross_entropy_loss(logits, labels, get_sequence_lengths(labels))\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (_, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits, labels)\n",
    "\n",
    "    return state, metrics"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.050245,
     "end_time": "2022-02-18T10:02:05.870504",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.820259",
     "status": "completed"
    },
    "tags": [],
    "id": "SE5zKSHYnKIz",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.738534Z",
     "iopub.execute_input": "2022-04-02T11:21:00.739801Z",
     "iopub.status.idle": "2022-04-02T11:21:00.751846Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.739705Z",
     "shell.execute_reply": "2022-04-02T11:21:00.750882Z"
    },
    "trusted": true
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(data, path=None, edit_path=None):\n",
    "    \"\"\"Train for a fixed number of steps and decode during training.\"\"\"\n",
    "    global MODEL_LINE_COUNT, O0_MODEL_LINE_COUNT, OUTPUT_TOKEN_COUNT\n",
    "\n",
    "    MODEL_LINE_COUNT, O0_MODEL_LINE_COUNT, OUTPUT_TOKEN_COUNT = next(data)\n",
    "\n",
    "    key = jax.random.PRNGKey(0)\n",
    "\n",
    "    decoder_shape = jnp.ones((BATCH_SIZE, 1, 128), jnp.float32)\n",
    "    dec_init = jnp.ones((BATCH_SIZE, OUTPUT_TOKEN_COUNT, 128))\n",
    "    # key, init_key = jax.random.split(key)\n",
    "    model = Model()\n",
    "\n",
    "    train_metrics = {\"loss\": [], \"accuracy\": [], \"perfect_accuracy\": []}\n",
    "    test_metrics = {\"accuracy\": [], \"perfect_accuracy\": []}\n",
    "\n",
    "    dropout_rng = jax.random.PRNGKey(42)\n",
    "    init_params = model.init({\"params\": key, 'dropout': dropout_rng}, decoder_shape, dec_init, False)\n",
    "    state = train_state.TrainState.create(apply_fn=model.apply, params=init_params[\"params\"],\n",
    "                                          tx=optax.adam(LEARNING_RATE))\n",
    "    if path is not None:\n",
    "        state = state.replace(params=load_model(path, state.params))\n",
    "    if edit_path is not None:\n",
    "        fd = flax.core.frozen_dict.FrozenDict({'EditEncoder_0': state.params['EditEncoder_0']})\n",
    "        state = state.replace(params=state.params.copy(load_model(edit_path, fd)))\n",
    "\n",
    "    for j in range(NUM_OF_EPOCH):\n",
    "        for i, (O0, outp) in zip(range(TRAIN_STEPS), data):\n",
    "            # palmtree_avg = jnp.repeat(jnp.mean(O0, axis=1, keepdims=True), repeats=OUTPUT_TOKEN_COUNT, axis=1)\n",
    "            palmtree_avg = jnp.tile(jnp.mean(O0, axis=1, keepdims=True), reps=(1, OUTPUT_TOKEN_COUNT, 1))\n",
    "            # palmtree_avg = np.tile(jnp.mean(O0, axis=1, keepdims=True), reps=(1,OUTPUT_TOKEN_COUNT,1))\n",
    "\n",
    "            state, metrics = train_step(state, {'answer': outp, 'embed': O0,\n",
    "                                                'dec_init': palmtree_avg})\n",
    "\n",
    "            train_metrics[\"loss\"].append(metrics[\"loss\"])\n",
    "            train_metrics[\"accuracy\"].append(metrics[\"token_accuracy\"])\n",
    "            train_metrics[\"perfect_accuracy\"].append(metrics[\"accuracy\"])\n",
    "\n",
    "            print(\n",
    "                f'Epoch {j} batch {i} loss: {metrics[\"loss\"]:.4f}, token_accuracy: {metrics[\"token_accuracy\"]:.4f}, perfect accuracy: {metrics[\"accuracy\"]:.4f}')\n",
    "            # print(\"EXAMPLE\", vocab.from_seq(jnp.argmax(metrics['example_out'][0][i], axis=-1)[\n",
    "            #                                 :get_sequence_lengths(metrics['example_out'][0][i][jnp.newaxis, :, :])[0]]))\n",
    "            # max_indices = jnp.argmax(metrics['example_out'][1][i], axis=-1)\n",
    "            # predicted = jax.nn.one_hot(max_indices, num_classes=VOCAB_SIZE)\n",
    "            # res_lengths = get_sequence_lengths(predicted[jnp.newaxis, :, :])\n",
    "            # print(\"RESULT\", vocab.from_seq(max_indices[:res_lengths[0]]))\n",
    "\n",
    "        save_model(state, f\"model-{j}.bin\")\n",
    "    #         metrics, examples = test_model(data, state, model, example_count=10)\n",
    "    #         test_metrics[\"accuracy\"].append(metrics[\"token accuracy\"])\n",
    "    #         test_metrics[\"perfect_accuracy\"].append(metrics[\"perfect accuracy\"])\n",
    "    #         print(\n",
    "    #             f'Epoch {j} test token accuracy: {metrics[\"token accuracy\"]:.4f}, perfect accuracy: {metrics[\"perfect accuracy\"]:.4f}')\n",
    "\n",
    "    #         print(\"Examples:\")\n",
    "    #         for expected, result in examples:\n",
    "    #             print(f\"Expected: {expected}\\n  Result: {result}\")\n",
    "    # Maybe save model here.\n",
    "    #         plot(train_metrics, test_metrics)\n",
    "    #         if j % 5 == 4:\n",
    "    #             save_model(state, f\"model-{j}.bin\")\n",
    "\n",
    "    return state, train_metrics, test_metrics\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.059473,
     "end_time": "2022-02-18T10:02:05.96114",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.901667",
     "status": "completed"
    },
    "tags": [],
    "id": "qc09Q4a9nKIz",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.753698Z",
     "iopub.execute_input": "2022-04-02T11:21:00.754198Z",
     "iopub.status.idle": "2022-04-02T11:21:00.774417Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.754162Z",
     "shell.execute_reply": "2022-04-02T11:21:00.773291Z"
    },
    "trusted": true
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot(train_metrics, test_metrics):\n",
    "    # Plotting the important metrics\n",
    "    fig, ax1 = plt.subplots()\n",
    "    plt.title(\"Train accuracy, perfect accuracy and loss\")\n",
    "    ax1.plot(train_metrics[\"loss\"])\n",
    "    ax1.set_ylabel(\"loss\")\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(train_metrics[\"accuracy\"])\n",
    "    ax2.plot(train_metrics[\"perfect_accuracy\"])\n",
    "    ax2.set_ylabel(\"accuracy\")\n",
    "    fig.tight_layout()\n",
    "    ax1.set_ylim(bottom=0)\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Test accuracy and perfect accuracy\")\n",
    "    plt.plot(list(zip(test_metrics[\"accuracy\"], test_metrics[\"perfect_accuracy\"])))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Train accuracy and test accuracy\")\n",
    "    train_accuracies = (sum(train_metrics[\"accuracy\"][i:i + TRAIN_STEPS]) / TRAIN_STEPS for i in\n",
    "                        range(0, len(train_metrics[\"accuracy\"]), TRAIN_STEPS))\n",
    "    plt.plot(list(zip(train_accuracies, test_metrics[\"accuracy\"])))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Train perfect accuracy and test perfect accuracy\")\n",
    "    train_accuracies = (sum(train_metrics[\"perfect_accuracy\"][i:i + TRAIN_STEPS]) / TRAIN_STEPS for i in\n",
    "                        range(0, len(train_metrics[\"perfect_accuracy\"]), TRAIN_STEPS))\n",
    "    plt.plot(list(zip(train_accuracies, test_metrics[\"perfect_accuracy\"])))\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "rQOzeB-unKI2",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.776184Z",
     "iopub.execute_input": "2022-04-02T11:21:00.776693Z",
     "iopub.status.idle": "2022-04-02T11:21:00.790207Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.776657Z",
     "shell.execute_reply": "2022-04-02T11:21:00.789118Z"
    },
    "trusted": true
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def test_model(data, state, model, example_count=0, eos_id=vocab.eos_index, generate_edit_representation_dataset=False):\n",
    "    results = []\n",
    "    example_iterator = iter(range(example_count))\n",
    "    accuracy = 0\n",
    "    perfect_accuracy = 0\n",
    "    test_num = 0\n",
    "    # edits = []\n",
    "    for test_num, (O0, O0_tok, outp) in zip(range(TEST_STEPS), data):\n",
    "        # palmtree_avg = jnp.repeat(jnp.mean(O0, axis=1, keepdims=True), repeats=OUTPUT_TOKEN_COUNT, axis=1)\n",
    "        # palmtree_avg = jnp.tile(jnp.mean(O0, axis=1, keepdims=True), reps=(1,OUTPUT_TOKEN_COUNT,1))\n",
    "        palmtree_avg = np.tile(jnp.mean(O0, axis=1, keepdims=True), reps=(1, OUTPUT_TOKEN_COUNT, 1))\n",
    "\n",
    "        logits, _ = model.apply({\"params\": state.params}, O0, palmtree_avg)\n",
    "        max_indices = jnp.argmax(logits, axis=-1)\n",
    "        #predicted = jax.nn.one_hot(max_indices, num_classes=VOCAB_SIZE)\n",
    "        #res_lengths = get_sequence_lengths(predicted)\n",
    "        for i, j in zip(range(BATCH_SIZE), example_iterator):\n",
    "            results.append(\n",
    "                (O0_tok[i],\n",
    "                 vocab.from_seq(jnp.argmax(outp[i], axis=-1)[:get_sequence_lengths(outp[i][jnp.newaxis, :, :])[0]]),\n",
    "                 vocab.from_seq(takewhile(lambda x: x != eos_id, max_indices[i]))))\n",
    "            if len(results[j][2]) != OUTPUT_TOKEN_COUNT:\n",
    "                results[j][2].append(\"<eos>\")\n",
    "\n",
    "        #product = jnp.sum(outp[max_indices], axis=-1)\n",
    "        correct_lengths = get_sequence_lengths(outp)\n",
    "        correctly_predicted_tokens = mask_sequences(\n",
    "            jnp.take_along_axis(outp, max_indices[:, :, jnp.newaxis], axis=2)[:, :, 0], correct_lengths)\n",
    "\n",
    "        accuracy += jnp.sum(correctly_predicted_tokens) / jnp.sum(correct_lengths)\n",
    "        perfect_accuracy += jnp.sum(jnp.sum(correctly_predicted_tokens, axis=1) == correct_lengths) / BATCH_SIZE\n",
    "\n",
    "    #         if generate_edit_representation_dataset:\n",
    "    #             edits.extend(zip(O0_tok, edit_repr.tolist(), O2_tok))\n",
    "\n",
    "    #     if generate_edit_representation_dataset:\n",
    "    #         with open('data.bin', 'wb') as f:\n",
    "    #             f.write(msgpack.packb(edits, use_bin_type=True))\n",
    "\n",
    "    return {'token accuracy': float(accuracy / (test_num + 1)),\n",
    "            'perfect accuracy': float(perfect_accuracy / (test_num + 1))}, results"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.051846,
     "end_time": "2022-02-18T10:02:06.045457",
     "exception": false,
     "start_time": "2022-02-18T10:02:05.993611",
     "status": "completed"
    },
    "tags": [],
    "id": "HOpFw2vknKI3",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.792263Z",
     "iopub.execute_input": "2022-04-02T11:21:00.792852Z",
     "iopub.status.idle": "2022-04-02T11:21:00.808545Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.792812Z",
     "shell.execute_reply": "2022-04-02T11:21:00.807745Z"
    },
    "trusted": true
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_and_test(data_path, model_paths, *args):\n",
    "    results = []\n",
    "    data = get_data(data_path)\n",
    "\n",
    "    MODEL_LINE_COUNT, O0_MODEL_LINE_COUNT, OUTPUT_TOKEN_COUNT = next(data)\n",
    "\n",
    "    decoder_shape = jnp.ones((BATCH_SIZE, 1, 128), jnp.float32)\n",
    "    dec_init = jnp.ones((BATCH_SIZE, 220, 128))\n",
    "    # key, init_key = jax.random.split(key)\n",
    "    model = Model()\n",
    "\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    init_params = model.init({\"params\": key}, decoder_shape, dec_init, False)\n",
    "    state = train_state.TrainState.create(apply_fn=model.apply, params=init_params[\"params\"],\n",
    "                                          tx=optax.adam(LEARNING_RATE))\n",
    "\n",
    "    for path in model_paths:\n",
    "        state = state.replace(params=load_model(path, state.params))\n",
    "\n",
    "        results.append(test_model(data, state, model, *args))\n",
    "        print(results[-1])\n",
    "\n",
    "        data = get_data(data_path)\n",
    "        next(data)\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:00.810029Z",
     "iopub.execute_input": "2022-04-02T11:21:00.810941Z",
     "iopub.status.idle": "2022-04-02T11:21:00.824801Z",
     "shell.execute_reply.started": "2022-04-02T11:21:00.810896Z",
     "shell.execute_reply": "2022-04-02T11:21:00.823873Z"
    },
    "trusted": true
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "data = get_data_epoch()\n\n# To use pretrained model\n\n#state, loss, accuracy, perfect_accuracy = train_model(data,\"../input/attentionmodel/model (2).bin\")\n\n#state, loss, accuracy, perfect_accuracy = train_model(data, edit_path = \"../input/attentionmodel/model_edit_2.bin\")\n\nstate, train_metrics, test_metrics = train_model(data)\n\nplot(train_metrics, test_metrics)",
   "metadata": {
    "papermill": {
     "duration": 5613.07501,
     "end_time": "2022-02-18T11:35:39.15357",
     "exception": false,
     "start_time": "2022-02-18T10:02:06.07856",
     "status": "completed"
    },
    "tags": [],
    "id": "itaL9N9_nKI4",
    "outputId": "4c8303c1-4a88-488c-cc53-a014b0581c2d",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:22:10.059937Z",
     "iopub.execute_input": "2022-04-02T11:22:10.060234Z",
     "iopub.status.idle": "2022-04-02T11:23:03.207784Z",
     "shell.execute_reply.started": "2022-04-02T11:22:10.060203Z",
     "shell.execute_reply": "2022-04-02T11:23:03.206488Z"
    },
    "trusted": true
   },
   "execution_count": 56,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# save_model(state)",
   "metadata": {
    "papermill": {
     "duration": 19.853206,
     "end_time": "2022-02-18T11:35:59.798532",
     "exception": true,
     "start_time": "2022-02-18T11:35:39.945326",
     "status": "failed"
    },
    "tags": [],
    "id": "_nyZXk6JnKI5",
    "execution": {
     "iopub.status.busy": "2022-04-02T11:21:54.382042Z",
     "iopub.status.idle": "2022-04-02T11:21:54.382419Z",
     "shell.execute_reply.started": "2022-04-02T11:21:54.382228Z",
     "shell.execute_reply": "2022-04-02T11:21:54.382248Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}